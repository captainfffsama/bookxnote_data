{"EpubVersion":1,"filepath":"","floatingtheme":[],"folded":false,"markups":[{"date":"2021-08-18 17:29:15","docid":0,"fillcolor":"ffff8280","id":3,"originaltext":"Since the general-izability of deep neural networks is difficult to control, ex-isting models such as autoencoder do not work well.","page":0,"textblocks":[{"first":[211.43629455566406,307.0065612792969,4.981292724609375,11.895355224609375],"last":[268.10357666015625,330.91754150390625,2.49066162109375,11.895355224609375],"length":133,"rects":[[211.43629455566406,307.0065612792969,74.92869567871094,11.895355224609375],[50.111961364746094,318.9615478515625,236.25308990478516,11.895355224609375],[50.111961364746094,330.91754150390625,220.4822769165039,11.895355224609375]],"start":537,"text":"Since the general-\nizability of deep neural networks is difficult to control, ex-\nisting models such as autoencoder do not work well."}],"title":"存在问题","type":5},{"annotations":[],"content":"重建类方法主体思想","date":"2021-08-18 17:32:39","docid":0,"fillcolor":"ffffed99","id":6,"linecolor":"ffff0000","originaltext":"It is generally assumed [57, 17, 55] that the re-construction error of the normal samples which are similarto the training data will be lower than abnormal samples.","page":0,"textblocks":[{"first":[345.4844970703125,642.0184936523438,3.317535400390625,12.00494384765625],"last":[542.6242065429688,665.9295043945312,2.49066162109375,12.00494384765625],"length":166,"rects":[[345.4844970703125,642.0184936523438,199.63055419921875,12.00494384765625],[308.86199951171875,653.9735107421875,236.25299072265625,12.00494384765625],[308.86199951171875,665.9295043945312,236.25286865234375,12.00494384765625]],"start":3093,"text":"It is generally assumed [57, 17, 55] that the re-\nconstruction error of the normal samples which are similar\nto the training data will be lower than abnormal samples."}],"title":"要点","type":5,"underline":true},{"content":"现在模型的一个弱点就是基于像素级的进行重建","date":"2021-08-18 17:41:38","docid":0,"fillcolor":"ffff8280","id":8,"originaltext":"We argue that the major weakness of existing memory-augmented models lies in the fact that they decode the en-coded feature maps in a per-pixel manner","page":1,"textblocks":[{"first":[62.06695556640625,618.1083374023438,9.404693603515625,12.00494384765625],"last":[209.1648406982422,642.018310546875,3.3175506591796875,12.00494384765625],"length":152,"rects":[[62.06695556640625,618.1083374023438,224.2979736328125,12.00494384765625],[50.11195373535156,630.0633544921875,236.2530975341797,12.00494384765625],[50.11195373535156,642.018310546875,162.3704376220703,12.00494384765625]],"start":1750,"text":"We argue that the major weakness of existing memory-\naugmented models lies in the fact that they decode the en-\ncoded feature maps in a per-pixel manner"}],"title":"存在问题","type":5}],"maxid":8,"position":{"x":0,"y":214},"title":"Divide_and_Assemble_Learning_Block-wise_Memory_for_Unsupervise_ Anomal_Detection","unimportant":[]}