{"EpubVersion":1,"filepath":"","floatingtheme":[],"folded":false,"markups":[{"date":"2021-08-18 17:29:15","docid":0,"fillcolor":"ffff8280","id":3,"originaltext":"Since the general-izability of deep neural networks is difficult to control, ex-isting models such as autoencoder do not work well.","page":0,"textblocks":[{"first":[211.43629455566406,307.0065612792969,4.981292724609375,11.895355224609375],"last":[268.10357666015625,330.91754150390625,2.49066162109375,11.895355224609375],"length":133,"rects":[[211.43629455566406,307.0065612792969,74.92869567871094,11.895355224609375],[50.111961364746094,318.9615478515625,236.25308990478516,11.895355224609375],[50.111961364746094,330.91754150390625,220.4822769165039,11.895355224609375]],"start":537,"text":"Since the general-\nizability of deep neural networks is difficult to control, ex-\nisting models such as autoencoder do not work well."}],"title":"存在问题","type":5},{"annotations":[],"content":"重建类方法主体思想","date":"2021-08-18 17:32:39","docid":0,"fillcolor":"ffffed99","id":6,"linecolor":"ffff0000","originaltext":"It is generally assumed [57, 17, 55] that the re-construction error of the normal samples which are similarto the training data will be lower than abnormal samples.","page":0,"textblocks":[{"first":[345.4844970703125,642.0184936523438,3.317535400390625,12.00494384765625],"last":[542.6242065429688,665.9295043945312,2.49066162109375,12.00494384765625],"length":166,"rects":[[345.4844970703125,642.0184936523438,199.63055419921875,12.00494384765625],[308.86199951171875,653.9735107421875,236.25299072265625,12.00494384765625],[308.86199951171875,665.9295043945312,236.25286865234375,12.00494384765625]],"start":3093,"text":"It is generally assumed [57, 17, 55] that the re-\nconstruction error of the normal samples which are similar\nto the training data will be lower than abnormal samples."}],"title":"要点","type":5,"underline":true},{"date":"2021-08-18 17:39:54","docid":0,"fillcolor":"ffffed99","id":7,"linecolor":"ffff0000","originaltext":"In particular, an externalmemory module is utilized to explicitly model the distribu-tion of normality. However, according to our investigation,the gap of reconstruction error can not be effectively en-larged in the existing works, leading to limited performanceimprovement. ","page":1,"textblocks":[{"first":[183.41151428222656,471.7303771972656,3.3175506591796875,12.00494384765625],"last":[105.43428039550781,531.50634765625,7.10333251953125,12.00494384765625],"length":280,"rects":[[183.41151428222656,471.7303771972656,102.95350646972656,12.00494384765625],[50.111968994140625,483.6863708496094,236.25302124023438,12.00494384765625],[50.111968994140625,495.641357421875,236.25302124023438,12.00494384765625],[50.111968994140625,507.5963134765625,236.25311279296875,12.00494384765625],[50.111968994140625,519.5513305664062,236.25311279296875,12.00494384765625],[50.111968994140625,531.50634765625,62.42564392089844,12.00494384765625]],"start":1131,"text":"In particular, an external\nmemory module is utilized to explicitly model the distribu-\ntion of normality. However, according to our investigation,\nthe gap of reconstruction error can not be effectively en-\nlarged in the existing works, leading to limited performance\nimprovement. "}],"type":5,"underline":true}],"maxid":7,"position":{"x":0,"y":214},"title":"Divide_and_Assemble_Learning_Block-wise_Memory_for_Unsupervise_ Anomal_Detection","unimportant":[]}