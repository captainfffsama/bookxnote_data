{"EpubVersion":1,"filepath":"","floatingtheme":[],"folded":false,"markups":[{"date":"2021-08-18 17:29:15","docid":0,"fillcolor":"ffff8280","id":3,"originaltext":"Since the general-izability of deep neural networks is difficult to control, ex-isting models such as autoencoder do not work well.","page":0,"textblocks":[{"first":[211.43629455566406,307.0065612792969,4.981292724609375,11.895355224609375],"last":[268.10357666015625,330.91754150390625,2.49066162109375,11.895355224609375],"length":133,"rects":[[211.43629455566406,307.0065612792969,74.92869567871094,11.895355224609375],[50.111961364746094,318.9615478515625,236.25308990478516,11.895355224609375],[50.111961364746094,330.91754150390625,220.4822769165039,11.895355224609375]],"start":537,"text":"Since the general-\nizability of deep neural networks is difficult to control, ex-\nisting models such as autoencoder do not work well."}],"title":"存在问题","type":5},{"annotations":[],"content":"重建类方法主体思想","date":"2021-08-18 17:32:39","docid":0,"fillcolor":"ffffed99","id":6,"linecolor":"ffff0000","originaltext":"It is generally assumed [57, 17, 55] that the re-construction error of the normal samples which are similarto the training data will be lower than abnormal samples.","page":0,"textblocks":[{"first":[345.4844970703125,642.0184936523438,3.317535400390625,12.00494384765625],"last":[542.6242065429688,665.9295043945312,2.49066162109375,12.00494384765625],"length":166,"rects":[[345.4844970703125,642.0184936523438,199.63055419921875,12.00494384765625],[308.86199951171875,653.9735107421875,236.25299072265625,12.00494384765625],[308.86199951171875,665.9295043945312,236.25286865234375,12.00494384765625]],"start":3093,"text":"It is generally assumed [57, 17, 55] that the re-\nconstruction error of the normal samples which are similar\nto the training data will be lower than abnormal samples."}],"title":"要点","type":5,"underline":true},{"content":"现在模型的一个弱点就是基于像素级的进行重建","date":"2021-08-18 17:41:38","docid":0,"fillcolor":"ffff8280","id":8,"originaltext":"We argue that the major weakness of existing memory-augmented models lies in the fact that they decode the en-coded feature maps in a per-pixel manner","page":1,"textblocks":[{"first":[62.06695556640625,618.1083374023438,9.404693603515625,12.00494384765625],"last":[209.1648406982422,642.018310546875,3.3175506591796875,12.00494384765625],"length":152,"rects":[[62.06695556640625,618.1083374023438,224.2979736328125,12.00494384765625],[50.11195373535156,630.0633544921875,236.2530975341797,12.00494384765625],[50.11195373535156,642.018310546875,162.3704376220703,12.00494384765625]],"start":1750,"text":"We argue that the major weakness of existing memory-\naugmented models lies in the fact that they decode the en-\ncoded feature maps in a per-pixel manner"}],"title":"存在问题","type":5},{"content":"小块表征能力有限，导致异常和正常在小块上有相同的模式","date":"2021-08-18 17:43:05","docid":0,"fillcolor":"ff60bb46","id":9,"originaltext":"The smallerthe block is, the more likely that anomaly shares the sameblock patterns with normality and thus can be reconstructedaccurately.","page":1,"textblocks":[{"first":[238.38514709472656,665.9293212890625,6.0871429443359375,12.00494384765625],"last":[90.40069580078125,701.7943725585938,2.4906463623046875,12.00494384765625],"length":142,"rects":[[238.38514709472656,665.9293212890625,47.97987365722656,12.00494384765625],[50.11195373535156,677.8843383789062,236.25315856933594,12.00494384765625],[50.11195373535156,689.83935546875,236.25303649902344,12.00494384765625],[50.11195373535156,701.7943725585938,42.779388427734375,12.00494384765625]],"start":2033,"text":"The smaller\nthe block is, the more likely that anomaly shares the same\nblock patterns with normality and thus can be reconstructed\naccurately."}],"title":"问题原因分析","type":5},{"CL":[49.576355861795385,329.6157714054504,54.266011146019274,264.6305481812051,54.266011146019274,257.9310406323138],"date":"2021-08-18 17:44:46","docid":0,"id":11,"linecolor":"ffd01a11","linewidth":7,"originaltext":"存在问题","page":0,"rect":[4.01970452933476,240.51232100519653,53.926109636241016,258.9310406323138],"type":9},{"CL":[49.576355861795385,693.0640559328017,50.246306616684514,722.8768645253679,50.246306616684514,729.5763720742591],"date":"2021-08-18 17:45:04","docid":0,"id":12,"linecolor":"ffd01a11","linewidth":7,"originaltext":"问题原因","page":1,"rect":[0,729.5763720742591,49.906405106906256,747.9950917013764],"type":9},{"date":"2021-08-18 17:46:54","docid":0,"fillcolor":"ffffed99","id":13,"linecolor":"ffff0000","originaltext":"skip con-nections can be added safely to improve the reconstructionquality of normal samples without reconstruction of abnor-mal samples.","page":1,"textblocks":[{"first":[508.1836853027344,326.27252197265625,3.875457763671875,12.00494384765625],"last":[358.4856872558594,362.1374816894531,2.49066162109375,12.00494384765625],"length":140,"rects":[[508.1836853027344,326.27252197265625,36.931488037109375,12.00494384765625],[308.8619384765625,338.2275085449219,236.25311279296875,12.00494384765625],[308.8619384765625,350.1824951171875,236.2530517578125,12.00494384765625],[308.8619384765625,362.1374816894531,52.114410400390625,12.00494384765625]],"start":3489,"text":"skip con-\nnections can be added safely to improve the reconstruction\nquality of normal samples without reconstruction of abnor-\nmal samples."}],"type":5,"underline":true},{"content":"小的异常贡献的误差被正常样本的累计误差给淹没了","date":"2021-08-18 17:49:37","docid":0,"fillcolor":"ffff8280","id":15,"originaltext":"In the real world, most anomalies such as scratch andcrack tend to be subtle and occupy an extremely smallregion.Therefore even in abnormal images, the pixelsare overwhelmed by normality rather than anomaly. Forreconstruction-based methods, the cumulative error fromnormal pixels contributes more than abnormal pixels, whichweakens the discriminativeness of the aggregated anomalyscore.","page":1,"textblocks":[{"first":[320.8169250488281,484.1453857421875,3.317535400390625,12.00494384765625],"last":[329.8830261230469,567.8313598632812,2.49066162109375,12.00494384765625],"length":393,"rects":[[320.8169250488281,484.1453857421875,224.29794311523438,12.00494384765625],[308.8619384765625,496.1003723144531,236.25299072265625,12.00494384765625],[308.8619384765625,508.05535888671875,236.2530517578125,12.00494384765625],[308.8619384765625,520.0113525390625,236.2529296875,12.00494384765625],[308.8619384765625,531.9663696289062,236.253173828125,12.00494384765625],[308.8619384765625,543.92138671875,236.25299072265625,12.00494384765625],[308.8619384765625,555.8763427734375,236.25299072265625,12.00494384765625],[308.8619384765625,567.8313598632812,23.511749267578125,12.00494384765625]],"start":4165,"text":"In the real world, most anomalies such as scratch and\ncrack tend to be subtle and occupy an extremely small\nregion.Therefore even in abnormal images, the pixels\nare overwhelmed by normality rather than anomaly. For\nreconstruction-based methods, the cumulative error from\nnormal pixels contributes more than abnormal pixels, which\nweakens the discriminativeness of the aggregated anomaly\nscore."}],"title":"存在问题2","type":5},{"CL":[545.6748898571938,494.088681730731,551.4729200527589,501.28818927962226,554.7241511805307,499.948287769844],"date":"2021-08-18 17:50:44","docid":0,"id":16,"linecolor":"ffd01a11","linewidth":7,"originaltext":"存在问题2","page":1,"rect":[554.7241511805307,490.7389279562854,612.6650392137728,510.15764758340265],"type":9},{"date":"2021-08-18 17:52:06","docid":0,"id":17,"imgfile":"ff6260db501cae15bf2493e5f7f1215e.png","linecolor":"ffa0ec6f","linewidth":2,"page":1,"rect":[305.4975442294418,189.93103901106744,549.6945943865286,482.3645435201713],"type":2},{"CL":[549.6945943865286,241.85222251497478,532.3743974060851,242.5221732698639,552.3743974060851,242.5221732698639],"date":"2021-08-18 17:52:26","docid":0,"id":19,"linecolor":"ffd01a11","linewidth":7,"originaltext":"问题1 解法","page":1,"rect":[552.3743974060851,233.81281345630526,612.6650392137727,252.2315330834226],"type":9},{"date":"2021-08-18 17:53:30","docid":0,"fillcolor":"ffa0ec6e","id":20,"originaltext":"Thus we introduce an adversariallylearned discriminator and exploit its low-dimensional se-mantic representation. The similarity between the featuresof the input image and the reconstructed image is treated asa measure of normality. The semantic feature-level anomalyscore is complementary with the low-level reconstruction-based score, and their combination further improves the de-tection performance.","page":1,"textblocks":[{"first":[406.53521728515625,591.7423706054688,6.087158203125,12.00494384765625],"last":[388.811767578125,675.4283447265625,2.49066162109375,12.00494384765625],"length":410,"rects":[[406.53521728515625,591.7423706054688,138.5797119140625,12.00494384765625],[308.8619384765625,603.6973876953125,236.2530517578125,12.00494384765625],[308.8619384765625,615.65234375,236.2530517578125,12.00494384765625],[308.8619384765625,627.6073608398438,236.25299072265625,12.00494384765625],[308.8619384765625,639.5623779296875,236.253173828125,12.00494384765625],[308.8619384765625,651.5183715820312,236.253173828125,12.00494384765625],[308.8619384765625,663.473388671875,236.2530517578125,12.00494384765625],[308.8619384765625,675.4283447265625,82.44049072265625,12.00494384765625]],"start":4699,"text":"Thus we introduce an adversarially\nlearned discriminator and exploit its low-dimensional se-\nmantic representation. The similarity between the features\nof the input image and the reconstructed image is treated as\na measure of normality. The semantic feature-level anomaly\nscore is complementary with the low-level reconstruction-\nbased score, and their combination further improves the de-\ntection performance."}],"type":5},{"CL":[545.6748898571938,619.3694728949978,561.4187325970883,664.5911488500138,561.4187325970883,671.2906563989051],"date":"2021-08-18 17:53:43","docid":0,"id":21,"linecolor":"ffd01a11","linewidth":7,"originaltext":"问题2解法","page":1,"rect":[511.17242598040366,671.2906563989051,568.1133140136458,689.7093760260224],"type":9},{"date":"2021-08-18 17:55:13","docid":0,"fillcolor":"ffffed99","id":24,"linecolor":"ffff0000","originaltext":" In-spired by the UNet architecture [38] which is widely usedfor dense prediction tasks, we insert skip connections atmultiple scales between the encoder and decoder. Usingskip connections provides substantial advantages via directinformation transfer between the layers.It can preserveboth local and global information, and hence yield betterreconstruction. However, it also brings a high risk of learn-ing an identity mapping from input to output, which wouldmake anomaly and normality inseparable as demonstratedin Figure 2. To address this issue, we equip all connectionsbetween the encoder and decoder with the block-wise mem-ory module, which is described in the following section.","page":3,"textblocks":[{"first":[530.470703125,183.38262939453125,3.02862548828125,12.004928588867188],"last":[530.2608642578125,326.84466552734375,2.49066162109375,12.00494384765625],"length":699,"rects":[[530.470703125,183.38262939453125,14.64508056640625,12.004928588867188],[308.862060546875,195.337646484375,236.25299072265625,12.004928588867188],[308.862060546875,207.29266357421875,236.2529296875,12.004928588867188],[308.862060546875,219.2476806640625,236.25311279296875,12.004928588867188],[308.862060546875,231.20367431640625,236.2530517578125,12.004928588867188],[308.862060546875,243.15869140625,236.25311279296875,12.004928588867188],[308.862060546875,255.11370849609375,236.25299072265625,12.00494384765625],[308.862060546875,267.0687255859375,236.25299072265625,12.00494384765625],[308.862060546875,279.0237121582031,236.25299072265625,12.00494384765625],[308.862060546875,290.9797058105469,236.25311279296875,12.00494384765625],[308.862060546875,302.9346923828125,236.2530517578125,12.00494384765625],[308.862060546875,314.8896789550781,236.2530517578125,12.00494384765625],[308.862060546875,326.84466552734375,223.88946533203125,12.00494384765625]],"start":3183,"text":" In-\nspired by the UNet architecture [38] which is widely used\nfor dense prediction tasks, we insert skip connections at\nmultiple scales between the encoder and decoder. Using\nskip connections provides substantial advantages via direct\ninformation transfer between the layers.It can preserve\nboth local and global information, and hence yield better\nreconstruction. However, it also brings a high risk of learn-\ning an identity mapping from input to output, which would\nmake anomaly and normality inseparable as demonstrated\nin Figure 2. To address this issue, we equip all connections\nbetween the encoder and decoder with the block-wise mem-\nory module, which is described in the following section."}],"type":5,"underline":true},{"date":"2021-08-18 17:57:51","docid":0,"id":26,"linecolor":"ffd01a11","linewidth":3,"originaltext":"用横连可以提重建效果，但是效果你懂的。所以加memory bank","page":3,"rect":[550.6995205188623,207.0147832607402,612.665039213773,234.47783807886069],"type":11},{"CL":[548.0197174993058,105.51724389503747,544.7684863715338,172.84729476139472,564.7684863715338,172.84729476139472],"date":"2021-08-18 17:58:56","docid":0,"id":27,"linecolor":"ffd01a11","linewidth":3,"originaltext":"问题2 解法","page":4,"rect":[564.7684863715338,168.4926148546154,592.2315411896542,178.20197466817405],"type":9},{"date":"2021-08-18 18:00:35","docid":0,"id":28,"imgfile":"89a61298a858c9a18c7655793bc773e3.png","linecolor":"ff5ac6ff","linewidth":2,"page":4,"rect":[432.1182369034868,297.7931105482169,493.0837555983973,332.2955744250069],"type":3},{"date":"2021-08-18 18:00:53","docid":0,"id":31,"imgfile":"9c6c83a0360befbf5dc9ba5a09297a4c.png","linearrow":true,"linecolor":"ff5ac6ff","linewidth":2,"page":4,"rect":[492.07882946606367,314.541879420445,516.8670073969613,314.541879420445],"type":1},{"date":"2021-08-18 18:01:01","docid":0,"id":32,"linecolor":"ffd01a11","linewidth":3,"originaltext":"对齐 loss","page":4,"rect":[519.2118350390731,310.1871995136657,542.9901607053034,319.89655932722434],"type":11},{"date":"2021-08-18 18:04:49","docid":0,"fillcolor":"ffffed99","id":34,"linecolor":"ffff0000","originaltext":"We believe that the reconstruction score R(x) based on theinput image and the reconstructed image can only attend tolarge or obvious anomalies. While the alignment score cal-culated in a low-dimensional space can further suppress theanomaly score of normality, especially for categories thatare difficult to reconstruct, such as leather and carpet.","page":7,"textblocks":[{"first":[308.86199951171875,524.406494140625,9.404693603515625,12.00494384765625],"last":[521.922119140625,584.1824951171875,2.49066162109375,12.00494384765625],"length":353,"rects":[[308.86199951171875,524.406494140625,236.24993896484375,12.00494384765625],[308.86199951171875,536.3615112304688,236.2530517578125,12.00494384765625],[308.86199951171875,548.3165283203125,236.2530517578125,12.00494384765625],[308.86199951171875,560.271484375,236.2530517578125,12.00494384765625],[308.86199951171875,572.2274780273438,236.2530517578125,12.00494384765625],[308.86199951171875,584.1824951171875,215.55078125,12.00494384765625]],"start":3040,"text":"We believe that the reconstruction score R(x) based on the\ninput image and the reconstructed image can only attend to\nlarge or obvious anomalies. While the alignment score cal-\nculated in a low-dimensional space can further suppress the\nanomaly score of normality, especially for categories that\nare difficult to reconstruct, such as leather and carpet."}],"type":5,"underline":true},{"date":"2021-08-18 18:06:49","docid":0,"id":35,"linecolor":"ffd01a11","linewidth":3,"originaltext":"其实对抗训练的主要目的是拿对齐损失来压缩异常分数","page":7,"rect":[553.8000132036213,520.5000124096873,611.2000145483022,561.4000133609775],"type":11}],"maxid":35,"position":{"x":0,"y":214},"title":"Divide_and_Assemble_Learning_Block-wise_Memory_for_Unsupervise_ Anomal_Detection","unimportant":[]}